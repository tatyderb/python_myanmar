# Верификация результатов

lesson = 1028051

## Верификация результатов

Не ошибается тот, кто ничего не делает. 

* Синтаксические ошибки - найдет интерпретатор, быстро.
* Логическая ошибка - программа работает, но не так, как нужно (описано в ТЗ или матмодели).
* Ошибка матмодели.

![https://xkcd.com/605/](https://stepik.org/media/attachments/lesson/1028051/50muzhey.png)

Подумайте, как можно обнаружить ошибки вашей модели? Как можно верифицировать данные вычислительного эксперимента и модели? Напишите ваши идеи в комментарии.

## Проверка кода

Пусть у вас есть функция `add(a, b)` в файле `calc.py`, которая должна складывать два числа. Как проверить, есть ошибки в её коде? 

### Вариант 1. Отладочная печать

```python
print(f'2 + 3 = {add(2, 3)}')
```
Очень плохо. Человек при каждом запуске должен в уме считать правильный результат. И осознавать - есть ошибка или нет. Легко пропустить ошибку.

### Вариант 1a. Отладочная печать с условиями

```python
if add(2, 3) != 5:
    print(f'Error: 2 + 3 = {add(2, 3)}')
else:
    print('OK')
```
Уже ясно, есть ошибка или нет, но еще нужно что-то считать в уме. *Хорошо, что мы не проверяем вычисление детерминанта матрицы 5х5.*

### Вариант 1b. Отладочная печать с условиями и ожидаемым результатом

```python
if add(2, 3) != 5:
    print(f'Error: add(2, 3) = {add(2, 3)} != 5')
else:
    print('OK')
```
* Плюс: есть имя функции, аргументы, при которых произошла ошибка, фактическое и ожидаемое значение.
* Минус: надо проверять есть или нет ошибка глазами. При отладке кода хочется, чтобы на ошибке сразу же останавливались.

### Вариант 2. assert

Если логическое выражение верное, то продолжается выполнение кода. Иначе программа останавливается и печатает сообщение об ошибке.
Файл `mytest.py`:
```python
import calc

assert calc.add(2, 3) == 5  # при ошибке программа остановится тут

print('Работаем дальше')    # и это не напечатает
```
напечатает:
```python
>python mytest.py
Traceback (most recent call last):
  File "C:\work\mytest.py", line 3, in <module>
    assert calc.add(2, 3) == 5
AssertionError
```
* Плюс: если много тестов, не надо следить глазами, где ОК, а где ошибка. У ошибки указано имя файла и строка в файле.

Добавим в `assert` сообщение в случае ошибки. Оно напечатается в AssertionError.

Файл `mytest.py:`
```python
import calc

assert calc.add(2, 3) == 5, f'Сложение целых положительных чисел'
```
напечатает
```python
>python mytest.py
Traceback (most recent call last):
  File "C:\work\mytest.py", line 3, in <module>
    assert calc.add(2, 3) == 5, f'Сложение целых положительных чисел'
AssertionError: Сложение целых положительных чисел
```

## Напишем тесты

С какими аргументами надо тестировать функцию add? Хватит ли одного теста.

У нас может быть сложная математическая функция, реализация которой содержит неочевидные ошибки. 

![сложная математическая формула](https://stepik.org/media/attachments/lesson/1028051/%D1%80%D0%B0%D1%81%D1%82%D0%B5%D1%80%D1%8F%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D1%8C.png)

Покажем на примере функции сложения развитие набора тестов. 

**Будем добавлять в набор тест и писать функцию сложения так, чтобы она была ошибочной, но проходила весь набор написанных тестов.**

### Тест первый, тривиальный.

```python
assert calc.add(2, 3) == 5
```
Начинайте с тривиальных тестов. Это хорошая практика. Помните, что единственный тест может пропустить код-"заглушку". 
```python
def add(a, b):
    return 5;
```

### Тест второй

```python
assert calc.add(2, 3) == 5
assert calc.add(12, 3) == 15
```

Использование того же слагаемого напрашивается на пропущенную ошибку:
 
```python
def add(a, b):
    return a + 3;
```
Вместо этого теста возьмем тест, больше отличающийся от первого.

### Тест второй, улучшенная версия

```python
assert calc.add(2, 3) == 5
assert calc.add(12, 8) == 20
```

Пытливые умы могут придраться к тому, что оба результата кратны 5 и придумать интересную формулу, но мы сделаем более простую ошибку:

```python
def add(a, b):
    return abs(a + b);
```

### Тест третий, отрицательная сумма

```python
assert calc.add(2, 3) == 5
assert calc.add(12, 8) == 20
assert calc.add(-12, 8) == -4
```

Тестирование - это во многом "переберите все варианты". Потому что:

```python
def add(a, b):
    return a + abs(b);
```

### Тест четвертый, отрицательные аргументы

```python
assert calc.add(2, 3) == 5
assert calc.add(12, 8) == 20
assert calc.add(-12, 8) == -4
assert calc.add(-12, -8) == -20
```

Теперь все? Нет, мы только начали.

```python
def add(a, b):
    return int(a + b);
```

### Тест пятый, нецелые числа

Надеюсь, вам уже хочется перебрать все вышеперечисленные варианты для чисел с плавающей точкой. Это хорошее желание, тестеры его одобряют, паранойя тоже.

Остановимся на другой проблеме.

```python
assert calc.add(0.1, 0.2) == 0.3
```
приводит к ошибке, даже для правильной функции сложения.
```python
    assert calc.add(0.1, 0.2) == 0.3
AssertionError
```
В тесте не хватает результат выполнения функций. То есть пока тест работает, все хорошо, но как только в тесте непонятная ошибка, нам не хватает информации. Что вернула функция, почему не 0.3?

Добавим в тест отладочную печать, для этого используем сообщение при `assert`:
```python
res = calc.add(0.1, 0.2)
assert res == 0.3, f'calc.add(0.1, 0.2) = {res} != 0.3'
```

получим:
```python
AssertionError: calc.add(0.1, 0.2) = 0.30000000000000004 != 0.3
```
**Никогда не сравнивайте числа с плавающей точкой на == и !=**, потому что такие числа [хранятся в компьютере](https://stepik.org/lesson/777150?unit=779631) с некоторой погрешностью. Напишем функцию сравнения чисел с плавающей точкой с заданной точностью.

```python
TOLERANCE = 1e-9

def float_equal(a: float, b: float, tolerance: float = TOLERANCE):
    return abs(a - b) < tolerance
    
assert float_equal(res, 0.3), f'calc.add(0.1, 0.2) = {res} != 0.3'
```

![105.3256 - 105.32](https://stepik.org/media/attachments/lesson/1028051/float_sub.jpg)

### Ошибки тестовых данных

При разработке тестов тоже появляются ошибки. Это **ошибки тестовых данных**. Например:

```python
assert calc.add(2, 3) == 123
```

## Требования к тестам

Мы видим, что код тестирования функции сложения больше, чем сама функция. **Это нормально.**

* Тестирование по объему превышает тестируемый код, но существенно проще в написании. 
* Тесты писать проще, если писать их сразу во время разработки, а не потом, через несколько месяцев. 
    * Если у вас есть маленькие тесты, локализующие проблему, то время на отладку ошибок **кода** (а не тестов) уменьшается.
    * Потом может оказаться, что встраивать маленькие тесты на функции (их называют unit test, юнит тест) в данную архитектуру неудобно, переделки занимаю много времени и затрагивают работоспособность тестируемого кода. *Проверено не одним коллективом программистов. Например, вы реализуете игру с пошаговым режимом, например [UNO](https://www.youtube.com/watch?v=sA5CtiLiD7M) (правила игры, [pdf](https://tesera.ru/images/items/96408/UNO.pdf) ). Если вы не задумываетесь о тестах, то начинаем реализацию с начала игры и первого хода. Если задумались, то пишем сначала load и save, при чем в человекочитаемом формате, например json, чтобы тесты любой игровой ситуации начинались с "загрузите состояние игры, где очередным ходом - эта ситуация". При работе в команде можно сразу поставить задачу "написать окончание игры и выяснение кто победил"*.
    
Требования к тестам:

* **Изолированность** (это про юнит-тесты, в интеграционных тестах наоборот, проверяют взаимодействие разных модулей системы). Тест должен затрагивать минимальное количество модулей, в идеале только один, на который пишем тест. *При тестировании сложения матриц лучше забейте матрицы руками в тест, а не тестируйте их чтение из БД. При тестировании работы с БД не надо тестировать операции над матрицами и вызвать модуль математических операций.*
* **Атомарность**. Тест должен быть достаточно маленьким, чтобы проверять один аспект функциональности. Только сложение, а не вычисление сразу со всеми арифметическими операциями и несколькими матфункциями. Если в таком мегатесте произошла ошибка, то мы можем только сказать "shit happens", но не можем сказать какое именно и где. *Мегатест тоже полезен, но вместе, а не вместо маленьких тестов. Особенно, если он проверяет почти всю функциональность, что маленькие тесты, но гораздо быстрее.*
* **Тестирование одного аспекта**. В тесте может быть чтение и печать матрицы, но если тест на сложение матриц, то мы считаем чтение матриц работающим кодом, который тестируем отдельно. Отдельный тест, что матрица корректно прочиталась, отдельный - что матрицы складываются корректно (или бросают ошибку, если не совпали размерности). В тесте на сложение мы не проверяем корректность чтения матрицы. Это уменьшит размер одного теста, но увеличит количество тестов.

Для того, чтобы писать, отлаживать и запускать тесты было удобно, используют тестовые фреймворки. На python это `unittest` (входит в стандартную поставку python), `noise` и `pytest`. Что дают фреймворки по сравнению с написанными выше набором `assert`:

* Удобный запуск 
    * одного теста, группы тестов, всех тестов файла, директории, множества директорий.
    * остановка после первой ошибки или прогон всех тестов с диагностикой (то, что сложение матриц не работает, не значит, что в вычислении производной нет ошибок).
    * Метки и тесты. На тесты можно навесить метки и запускать только тесты с указанной меткой или исключая эту метку. Удобно для отдельного запуска или исключения долгих тестов или тестов, работающих с БД.
* Удобные отчеты о выполнении тестов.
* Показ кода теста и стека вызова функций при тесте, настраиваемое логирование и запись результатов тестирования.
* Параметризация тестов. Один тест мы запускаем с разными параметрами (например, тест на вычисление детерминанта можно запускать для разных наборов входных матриц и ожидаемых значений).
* Проверка исключений. Да, их тоже надо протестировать.
* setup + cleanup - подготовка тестовых данных и зачистка результатов.
* mock - "заглушки". Для тестирования функции оформления заказа в интернет-магазине мы не шлем запрос в банк и не трогаем реальные деньги. Достаточно заглушки, которая будет эмулировать запрос в банк и возвращать состояния "успешная оплата" и "оплата не прошла".
* Легкое встраивание в процесс непрерывной разработки (CI/CD).
* Другие удобные функции. Напишите в комментариях, если мы забыли что-то существенное.

## Интересные материалы

* [Почему юнит-тесты не работают в научных приложениях](https://habr.com/ru/articles/92038/), статья на Хабре.